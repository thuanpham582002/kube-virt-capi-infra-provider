---
apiVersion: cluster.x-k8s.io/v1beta1
kind: Cluster
metadata:
  name: "${CLUSTER_NAME}"
spec:
  clusterNetwork:
    pods:
      cidrBlocks:
        - 10.243.0.0/16
    services:
      cidrBlocks:
        - 10.95.0.0/16
  infrastructureRef:
    apiVersion: infrastructure.cluster.x-k8s.io/v1alpha1
    kind: KubevirtCluster
    name: '${CLUSTER_NAME}'
    namespace: "${NAMESPACE}"
  controlPlaneRef:
    apiVersion: controlplane.cluster.x-k8s.io/v1alpha3
    kind: TalosControlPlane
    name: ${CLUSTER_NAME}-controlplane
    namespace: "${NAMESPACE}"
---
apiVersion: infrastructure.cluster.x-k8s.io/v1alpha1
kind: KubevirtCluster
metadata:
  name: "${CLUSTER_NAME}"
  namespace: "${NAMESPACE}"
spec:
  controlPlaneServiceTemplate:
    spec:
      type: LoadBalancer
---
apiVersion: infrastructure.cluster.x-k8s.io/v1alpha1
kind: KubevirtMachineTemplate
metadata:
  name: "${CLUSTER_NAME}-control-plane-${TALOS_CODE}"
  namespace: "${NAMESPACE}"
spec:
  template:
    spec:
      virtualMachineBootstrapCheck:
        checkStrategy: none
      virtualMachineTemplate:
        metadata:
          namespace: "${NAMESPACE}"
        spec:
          instancetype:
            kind: VirtualMachineClusterInstancetype
            name: "${INSTANCE_TYPE}"
          preference:
            kind: VirtualMachineClusterPreference
            name: "${INSTANCE_PREFERENCE}"
          dataVolumeTemplates:
          - metadata:
              name: "boot-volume"
            spec:
              pvc:
                volumeMode: Block
                accessModes:
                - ReadWriteOnce
                resources:
                  requests:
                    storage: "${ROOT_VOLUME_SIZE}"
                storageClassName: "${STORAGE_CLASS_NAME}"
              source:
                pvc:
                  name: ${NODE_VM_IMAGE_TEMPLATE}
                  # namespace: golden-images
          runStrategy: Always
          template:
            spec:
              domain:
                devices:
                  networkInterfaceMultiqueue: true
                  disks:
                    - disk:
                        bus: virtio
                      name: dv-volume
              evictionStrategy: External
              volumes:
                # - name: serviceaccount
                #   serviceAccount:
                #     serviceAccountName: cdi-cloner
                - dataVolume:
                    name: "boot-volume"
                  name: dv-volume
---
kind: TalosControlPlane
apiVersion: controlplane.cluster.x-k8s.io/v1alpha3
metadata:
  name: ${CLUSTER_NAME}-controlplane
  namespace: "${NAMESPACE}"
spec:
  version: ${KUBERNETES_VERSION}
  replicas: ${CONTROL_PLANE_MACHINE_COUNT}
  infrastructureTemplate:
    kind: KubevirtMachineTemplate
    apiVersion: infrastructure.cluster.x-k8s.io/v1alpha1
    name: "${CLUSTER_NAME}-control-plane-${TALOS_CODE}"
    namespace: "${NAMESPACE}"
  controlPlaneConfig:
    controlplane:
      generateType: controlplane
      talosVersion: ${TALOS_VERSION}
      configPatches:
        - op: add
          path: /cluster/network/cni
          value: 
            name: none
        - op: add
          path: /cluster/inlineManifests
          value:
          - name: cilium-install
            contents: |
              ---
              apiVersion: rbac.authorization.k8s.io/v1
              kind: ClusterRoleBinding
              metadata:
                name: cilium-install
              roleRef:
                apiGroup: rbac.authorization.k8s.io
                kind: ClusterRole
                name: cluster-admin
              subjects:
              - kind: ServiceAccount
                name: cilium-install
                namespace: kube-system
              ---
              apiVersion: v1
              kind: ServiceAccount
              metadata:
                name: cilium-install
                namespace: kube-system
              ---
              apiVersion: batch/v1
              kind: Job
              metadata:
                name: cilium-install
                namespace: kube-system
              spec:
                backoffLimit: 10
                template:
                  metadata:
                    labels:
                      app: cilium-install
                  spec:
                    restartPolicy: OnFailure
                    tolerations:
                      - operator: Exists
                      - effect: NoSchedule
                        operator: Exists
                      - effect: NoExecute
                        operator: Exists
                      - effect: PreferNoSchedule
                        operator: Exists
                      - key: node-role.kubernetes.io/control-plane
                        operator: Exists
                        effect: NoSchedule
                      - key: node-role.kubernetes.io/control-plane
                        operator: Exists
                        effect: NoExecute
                      - key: node-role.kubernetes.io/control-plane
                        operator: Exists
                        effect: PreferNoSchedule
                    affinity:
                      nodeAffinity:
                        requiredDuringSchedulingIgnoredDuringExecution:
                          nodeSelectorTerms:
                            - matchExpressions:
                                - key: node-role.kubernetes.io/control-plane
                                  operator: Exists
                    serviceAccount: cilium-install
                    serviceAccountName: cilium-install
                    hostNetwork: true
                    containers:
                    - name: cilium-install
                      image: quay.io/cilium/cilium-cli-ci:latest
                      env:
                      - name: KUBERNETES_SERVICE_HOST
                        valueFrom:
                          fieldRef:
                            apiVersion: v1
                            fieldPath: status.podIP
                      - name: KUBERNETES_SERVICE_PORT
                        value: "6443"
                      command:
                      - cilium
                      - install
                      - --set
                      - ipam.mode=kubernetes
                      - --set
                      - kubeProxyReplacement=true
                      - --set
                      - securityContext.capabilities.ciliumAgent={CHOWN,KILL,NET_ADMIN,NET_RAW,IPC_LOCK,SYS_ADMIN,SYS_RESOURCE,DAC_OVERRIDE,FOWNER,SETGID,SETUID}
                      - --set
                      - securityContext.capabilities.cleanCiliumState={NET_ADMIN,SYS_ADMIN,SYS_RESOURCE}
                      - --set
                      - cgroup.autoMount.enabled=false
                      - --set
                      - cgroup.hostRoot=/sys/fs/cgroup
                      - --set
                      - k8sServiceHost=localhost
                      - --set
                      - k8sServicePort=7445
                      - --set
                      - bpf.hostLegacyRouting=false
                      - --set
                      - bpf.masquerade=true
                      - --set
                      - nodePort.enabled=true
                      - --set
                      - routingMode=tunnel
                      - --set
                      - tunnelProtocol=geneve
                      - --set
                      - socketLB.enabled=true
                      - --set
                      - hubble.enabled=true
                      - --set
                      - hubble.relay.enabled=true
        - op: add
          path: /cluster/proxy/disabled
          value: true
---
apiVersion: infrastructure.cluster.x-k8s.io/v1alpha1
kind: KubevirtMachineTemplate
metadata:
  name: "${CLUSTER_NAME}-md-0-${TALOS_CODE}"
  namespace: "${NAMESPACE}"
spec:
  template:
    spec:
      virtualMachineBootstrapCheck:
        checkStrategy: none
      virtualMachineTemplate:
        metadata:
          namespace: "${NAMESPACE}"
          labels:
            app: ${CLUSTER_NAME}-md-0
        spec:
          instancetype:
            kind: VirtualMachineClusterInstancetype
            name: "${INSTANCE_TYPE}"
          preference:
            kind: VirtualMachineClusterPreference
            name: "${INSTANCE_PREFERENCE}"
          dataVolumeTemplates:
          - metadata:
              name: "boot-volume"
            spec:
              pvc:
                volumeMode: Block
                accessModes:
                - ReadWriteOnce
                resources:
                  requests:
                    storage: "${ROOT_VOLUME_SIZE}"
                storageClassName: "${STORAGE_CLASS_NAME}"
              source:
                pvc:
                  name: ${NODE_VM_IMAGE_TEMPLATE}
                  # namespace: golden-images
          runStrategy: Always
          template:
            metadata:
              labels:
                app: ${CLUSTER_NAME}-md-0
            spec:
              affinity:
                podAntiAffinity: ## set the anti-affinity rule to spread the pods across nodes
                  preferredDuringSchedulingIgnoredDuringExecution: ## pods will be scheduled on the same node if number if nodes are not matching the number of replicas
                  - weight: 100
                    podAffinityTerm:
                      labelSelector:
                        matchExpressions:
                        - key: app
                          operator: In
                          values:
                          - ${CLUSTER_NAME}-md-0
                      topologyKey: kubernetes.io/hostname   
              domain:
                devices:
                  networkInterfaceMultiqueue: true
                  disks:
                    - disk:
                        bus: virtio
                      name: dv-volume
              evictionStrategy: External
              volumes:
                # - name: serviceaccount
                #   serviceAccount:
                #     serviceAccountName: cdi-cloner
                - dataVolume:
                    name: "boot-volume"
                  name: dv-volume
---
apiVersion: bootstrap.cluster.x-k8s.io/v1alpha3
kind: TalosConfigTemplate
metadata:
  name: "${CLUSTER_NAME}-md-0-${TALOS_CODE}"
spec:
  template:
    spec:
      generateType: join
      talosVersion: ${TALOS_VERSION}
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: MachineDeployment
metadata:
  labels:
    cluster.x-k8s.io/cluster-name: ${CLUSTER_NAME}
  name: "${CLUSTER_NAME}-md-0"
  namespace: "${NAMESPACE}"
spec:
  clusterName: "${CLUSTER_NAME}"
  replicas: ${WORKER_MACHINE_COUNT}
  selector:
    matchLabels:
      cluster.x-k8s.io/cluster-name: ${CLUSTER_NAME}
  template:
    metadata:
      labels:
        cluster.x-k8s.io/cluster-name: ${CLUSTER_NAME}
        node-role.kubernetes.io/worker: ''
    spec:
      clusterName: "${CLUSTER_NAME}"
      version: "${KUBERNETES_VERSION}"
      bootstrap:
        configRef:
          apiVersion: bootstrap.cluster.x-k8s.io/v1alpha3
          kind: TalosConfigTemplate
          name: "${CLUSTER_NAME}-md-0-${TALOS_CODE}"
      infrastructureRef:
        name: "${CLUSTER_NAME}-md-0-${TALOS_CODE}"
        namespace: "${NAMESPACE}"
        apiVersion: infrastructure.cluster.x-k8s.io/v1alpha1
        kind: KubevirtMachineTemplate
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: MachineHealthCheck
metadata:
  name: ${CLUSTER_NAME}-md-0
  namespace: "${NAMESPACE}"
spec:
  clusterName: ${CLUSTER_NAME}
  maxUnhealthy: 100%
  nodeStartupTimeout: 10m
  selector:
    matchLabels:
      cluster.x-k8s.io/deployment-name: ${CLUSTER_NAME}-md-0
  unhealthyConditions:
  - type: Ready
    status: Unknown
    timeout: 300s
  - type: Ready
    status: "False"
    timeout: 300s